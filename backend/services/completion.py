import asyncio
import time
import os
import uuid
from typing import List

from openai import AsyncOpenAI
from sqlalchemy.orm import Session

import backend.models as mdl

import backend.utils.logger as lg
from backend.utils.history import get_history, set_history
from backend.utils.streamer import chunk
from backend.utils.tool_pools import choose_tools

from backend.services.tools import get_tools_by_ids

from agents.main import AsyncSimpleAgent
from agents.tools import ToolSpec, ToolResponse


async def chat_completion(
    session: Session,
    request_id: str,
    user_profile: mdl.User,
    body: mdl.PostGenerateCompletionRequest
):
    start = time.time()
    lg.logger.info(
f"""
---
ğŸ’¬ API: Chat Completion
ìœ ì €: {user_profile.username}
ì§ˆë¬¸: {body.messages[0].content.parts[0]}
ì‚¬ìš©ì˜ˆì • LLM: {body.llm.deployment_id}
ì‚¬ìš©ì˜ˆì • ë„êµ¬ID: {body.tools}
ì‹œì‘ì‹œê°„: {start:.2f}
---
"""
    )
    yield await chunk(
        event="start", 
        data={"message": ""}, 
    )
    await asyncio.sleep(0.02)
    history, err = get_history(
        session=session,
        user_id=user_profile.user_id,
        conversation_id=body.conversation_id,
        request_id=request_id,
        parent_message_id=body.parent_message_id
    )
    if err:
        lg.logger.error(
f"""
Raises
---
ìœ„ì¹˜: get_history
ìœ ì €: {user_profile.username}
ì˜¤ë¥˜ ë©”ì‹œì§€: {err}
---
"""
        )
        yield await chunk(
            "error", 
            {"message": "âŒ ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."},
        )
        await asyncio.sleep(0.1)
        return
    tools, err = get_tools_by_ids(session=session, tool_ids=[t.tool_id for t in body.tools])
    if err:
        lg.logger.error(
f"""
Raises
---
ìœ„ì¹˜: get_tools_by_ids
ìœ ì €: {user_profile.username}
ì˜¤ë¥˜ ë©”ì‹œì§€: {err}
---
"""
        )
        yield await chunk(
            "error", 
            {"message": "âŒ ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."},
        )
        await asyncio.sleep(0.1)
        return
    
    
    yield await chunk(
        event="status", 
        data={"message": "ğŸ§ ì‚¬ìš©ìë‹˜ì˜ ì§ˆë¬¸ì„ ë¶„ì„ì¤‘ì…ë‹ˆë‹¤..."}, 
    )
    await asyncio.sleep(0.1)
    lg.logger.info(
f"""
---
ğŸ› ï¸ íˆìŠ¤í† ë¦¬ì™€ ì‚¬ìš©í•  ë„êµ¬ì˜ ìŠ¤í™ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.
ìœ ì €: {user_profile.username}
ê±¸ë¦° ì‹œê°„: {time.time() - start:.2f}ì´ˆ
---
"""
    )
    if len(tools) == 0:
        yield await chunk(
            event="status", 
            data={"message": (
f"""
ğŸ’­ ì‚¬ìš©ìë‹˜ì€ ë”°ë¡œ ë„êµ¬ì‚¬ìš©ì„ ì•ˆí•˜ì…¨ì–´...
â˜ºï¸ ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©ìë‹˜ì˜ ì§ˆë¬¸ì„ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤!
"""
            )}, 
        )
    else:  
        yield await chunk(
            event="status", 
            data={"message": (
f"""
ğŸ’­ ì‚¬ìš©ìë‹˜ì€ ë‹¤ìŒê³¼ ê°™ì€ ë„êµ¬ë“¤ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸°ë¥¼ ì›í•˜ì‹œê³  ê³„ì…”...

{", ".join([f"ğŸ› ï¸ {t.tool_name}" for t in tools]) if tools else "ì‚¬ìš©í•  ë„êµ¬ê°€ ì—†ìŠµë‹ˆë‹¤."}

â˜ºï¸ ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©ìë‹˜ì˜ ì§ˆë¬¸ì„ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤!
"""
            )}, 
        )
    
    user_message_id = str(uuid.uuid4())
    assaistant_message_id = str(uuid.uuid4())
    new_messages = []

    user = mdl.Message.user_message(
        message_id=user_message_id,
        parent_message_id=body.parent_message_id,
        agent_id=None,
        content=body.messages[0].content,
    )
    new_messages.append(user)
    await history.update_context(
        current_user_message=user, 
        parent_message_id=body.parent_message_id
    )
    lg.logger.info(
f"""
---
ğŸ“Š í˜„ì¬ íˆìŠ¤í† ë¦¬ì˜ ë§¥ë½(ì»¨í…ìŠ¤íŠ¸)ë¥¼ ì—…ë°ì´íŠ¸ ì™„ë£Œí•˜ì˜€ìŠµë‹ˆë‹¤.
ìœ ì €: {user_profile.username}
ê±¸ë¦° ì‹œê°„: {time.time() - start:.2f}ì´ˆ
---
"""
    )
    yield await chunk(
        event="status", 
        data={"message": (
f"""
ğŸ’­ ì‚¬ìš©ìë‹˜ì€ **{history.intent}**ë¥¼ í•˜ê³ ì í•˜ì…”... ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ ì–´ë–¤ í•´ê²°ì±…ì´ ìˆì„ê¹Œ? ğŸ¤”
"""
        )}, 
    )
    await asyncio.sleep(0.02)
    selected_tools = [
        ToolSpec.model_validate(tool) 
        for tool in await choose_tools(tools)
    ]
    simple_agent = AsyncSimpleAgent(
        provider=AsyncOpenAI(
            api_key=os.getenv("OPENAI_API_KEY")
        ),
        tools=selected_tools,
        user_context=history.get_context() or "ì‚¬ìš©ì ë§¥ë½ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    )
    
    messages = [{"role": "system", "content": body.messages[0].content.parts[0]}]
    messages.extend(history.marshal_to_messagelike(user))
    lg.logger.info(
f"""
---
ğŸ¤– í˜„ì¬ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì˜ˆì •ì…ë‹ˆë‹¤...
ìœ ì €: {user_profile.username}
ê±¸ë¦° ì‹œê°„: {time.time() - start:.2f}ì´ˆ
---
"""
    )
    gen = simple_agent.astream_v2(
        messages=messages,
        deployment_id=body.llm.deployment_id
    )
    
    parts = ""
    tool_results: List[ToolResponse] = []
    async for response in gen:
        if response['type'] == 'tool':
            tool_results.append(ToolResponse.model_validate_json(response['content']))
        elif response['type'] == 'delta':
            yield await chunk(
                event="data",
                data={"message": response['content']}
            )
            await asyncio.sleep(0.02)
            lg.logger.debug(f"Streaming: {response['content']}")
            parts += response['content']
        elif response['type'] == 'done':
            yield await chunk(
                event="done",
                data={"message": response['content']}
            )
            await asyncio.sleep(0.1)
        elif response['type'] == 'status':
            yield await chunk(
                event="status",
                data={"message": response['content']}
            )
            await asyncio.sleep(0.1)
        elif response['type'] == 'error':
            lg.logger.error(
f"""
Raises
---
ìœ„ì¹˜: get_tools_by_ids
ìœ ì €: {user_profile.username}
ì˜¤ë¥˜ ë©”ì‹œì§€: {err}
---
"""
            )
            yield await chunk(
                event="error",
                data={"message": response['content']}
            )
            return

        await asyncio.sleep(0.02)

    final_tool_id = None
    final_tool_result = None
    for resp in tool_results:
        for t in tools:
            if resp.name == t.tool_name:
                lg.logger.info(
f"""
---
ğŸ› ï¸ í•´ë‹¹ ë„êµ¬: {t.tool_name}ì— ëŒ€í•´ ì‘ì—…ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ê°™ìŠµë‹ˆë‹¤.
ìœ ì €: {user_profile.username}
ê±¸ë¦° ì‹œê°„: {time.time() - start:.2f}ì´ˆ
ë„êµ¬ ê²°ê³¼ ì•ë¶€ë¶„: {resp.output[:100]}...
---
"""
    )
                final_tool_id = t.tool_id
                final_tool_result = resp.output
                break
            
    assistant = mdl.Message.assistant_message(
        message_id=assaistant_message_id,
        parent_message_id=user_message_id,
        content=mdl.Content(type='text', parts=[parts]),
        llm_deployment_id=body.llm.deployment_id,
        tool_id=final_tool_id,
        tool_result=final_tool_result
    )
    new_messages.append(assistant)

    err = set_history(
        session=session,
        history=history,
        new_messages=new_messages,
        request_id=request_id,   
        conversation_type='chat'
    )
    if err:
        lg.logger.error(
            f"Error setting history for user {user_profile.user_id} in conversation {body.conversation_id}: {err}"
        )
        yield await chunk(
            "error", 
            {"message": "âŒ Server sent error... Retry later."},
        )
        return
    
    lg.logger.info(
f"""
---
ğŸ’¬ API: Chat Completion ì™„ë£Œ
ìœ ì €: {user_profile.username}
ê±¸ë¦° ì‹œê°„: {time.time() - start:.2f}ì´ˆ
---
"""
    )